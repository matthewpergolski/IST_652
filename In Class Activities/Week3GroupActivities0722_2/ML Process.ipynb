{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4a6cbc-effe-4a27-833e-82a5887024ce",
   "metadata": {},
   "source": [
    "# Machine Learning Process\n",
    "- Data Collection\n",
    "    - Gather data through static files, via database, or other means\n",
    "- Data Exploration\n",
    "    - Summarize and describe data\n",
    "        - str/summary in R; .info()/.describe() in python\n",
    "    - Visualize variables for:\n",
    "        - Comparison (boxplot)\n",
    "        - Relationship (scatter/line plots)\n",
    "        - Distribution (histogram)\n",
    "        - Composition (stacked bar chart)\n",
    "- Data Preparation\n",
    "    - Data quality issues (missing values -- removing or estimating through median/mean/mode)\n",
    "    - Normalize data\n",
    "        - z-score\n",
    "        - min/max\n",
    "        - log\n",
    "    - Sample data to split into train, test sets\n",
    "        - 75% test, 25% train\n",
    "- Classification/Regression Modeling\n",
    "    - Supervised ML\n",
    "    - Classification = categorical predicting\n",
    "    - Regression = numerical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be87ece7-3e94-4f46-8317-26bd1b878cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede690c0-7443-427e-971c-19b2923b0f9d",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms\n",
    "- Association Rule Mining\n",
    "    - apriori()\n",
    "- Clustering\n",
    "    - K-Means\n",
    "    - Hierarchical\n",
    "- Decision Tree\n",
    "- Naive Bayes\n",
    "- SVM\n",
    "- KNN\n",
    "- Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e07026-8140-41b8-b69c-07b959ae17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc17d5-c725-423c-b6bb-51d21dd08f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "### Tokenizing -- split text up by word and/or sentence (= how words relate to each other, figure out context)\n",
    "### Remove stop words\n",
    "### Stemming/lemmatizing -- breaking words down to singular meaning: Discoveries/Discovery = Discover\n",
    "### Tagging/chunking -- grouping words together to create context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca8c5b-c4cc-466a-90f8-e2da5a6ad9df",
   "metadata": {},
   "source": [
    "Association Rule Mining\n",
    "- deploys pattern recognition to idenity and quanityf relationships between items\n",
    "- apriori algorithm\n",
    "- Support\n",
    "    - frequency of an item (how popular the item is)\n",
    "- Confidence\n",
    "    - How likely one item is to be grouped wit hanother (how often are eggs bought with milk)\n",
    "- Lift\n",
    "    - If Lift score is > 1, A is highly bought with C\n",
    "    - If lift < 1, A is almost never bought with C\n",
    "    - Lift = 1, then no association between items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de76f78-2c71-4524-901b-6997ad061cd6",
   "metadata": {},
   "source": [
    "Neural Network\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ebe929-2ed1-4423-b4ec-f66f9bc64fbf",
   "metadata": {},
   "source": [
    "KNN\n",
    "- memorizes observations from within a labled dataset to predict classification albels for new, unlabeled observations\n",
    "- The more similar the observation values, the more likely they will be calssified with the same level\n",
    "- pattern recognition\n",
    "- popular use cases; stock price prediction, credit risk analysis\n",
    "- Assumptions\n",
    "    - little noise\n",
    "    - releveant features\n",
    "    - smaller dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64b452-bfa7-4c63-b3d8-46f40e65b5e1",
   "metadata": {},
   "source": [
    "Decision Tree\n",
    "- models decision points to predict probably outcomes\n",
    "- nodes\n",
    "    - root\n",
    "        - represents entire sample/pop\n",
    "    - decision\n",
    "        - split into sub nodes -- base of tree\n",
    "    - leaf\n",
    "        - no longer split -- end points\n",
    "- Supervised\n",
    "- Useful for nonlinear data\n",
    "    - categorical (classification) and continuous (numerical target variable) output variables\n",
    "- 'Mirror human thinking' -- more easily interpreted by humans, generally\n",
    "- one hot encoding generally not needed -- can implement on categoricla variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc06a-fc7c-4dc2-bb06-63e4e35bd65a",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers (bayesian statistics vs frequentist approach)\n",
    "   - predict the liklihood that an event will occur given evidence that's present in your data\n",
    "   - supervised classification model\n",
    "   - Three types\n",
    "        - mulitnomial\n",
    "            - categorial or continuous and describe discrete frequency counts\n",
    "        - bernoulli\n",
    "            - binary\n",
    "        - gaussian\n",
    "            - normally distributed feature\n",
    "   - use cases\n",
    "        - spam detection\n",
    "        - csutomer classification\n",
    "        - health risk calssification\n",
    "        \n",
    "   - assumption\n",
    "       - predictors are independent of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a2b12-1da5-46cb-8e19-6b6b7b0da67b",
   "metadata": {},
   "source": [
    "Ensemble with Random Forests\n",
    "- many decision trees that are used to create a singular, accurate tree\n",
    "- combine several base models to produce one optimal predictive model\n",
    "- improve overall performacne through comibning decisions from multiple models\n",
    "- generating multiple models to generate a singular model that's more reliable and accurate\n",
    "    - can be the same algorithm more than once\n",
    "    - or many aggergated models\n",
    "- Types of ensemble meethods\n",
    "    - bagging\n",
    "        - takes results from multiple models and combines them to get a final result\n",
    "        - decision trees typically used with bagging\n",
    "        - create subsets of data set adn run different models on the these; aggregate result, then run the models in parallel\n",
    "        - process\n",
    "            - train/test sets\n",
    "            - multiple subsets are created from training data\n",
    "            - model is then trained on subset\n",
    "            - aggregate results\n",
    "    - boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
